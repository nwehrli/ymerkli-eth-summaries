\section*{Basics}
%-------------------------------------------------------------------------------------------
%PROBABILITIES
%-------------------------------------------------------------------------------------------
% $P(X,Y)=P(X|Y)P(Y)=P(Y|X)P(X)\\
% P(X,Y|Z)=P(X|Y,Z)P(Y|Z)\\
% P(X,Y|Z)=P(Y|X,Z)P(X|Z)$\\
% $P(X,Y,Z)=P(X|Y,Z)P(Y|Z)P(Z)$\\
% $\text{X,Y iid:}P(X,Y|Z)=P(X|Z)P(Y|Z)$\\
% $P(X=x)=\sum_{y'\in Y}P(X=x,Y=y')$\\
% $\text{iid:}P(X_1,...,X_n|Y)=\prod_{i=1}^{n}P(X_i|Y)$\\
% $\mathbb{E}_x[X] = \begin{cases}
% \int x \cdot p(x) \partial x  &|\mathbb{E}_x[f(x)] =\\
% \sum_x x \cdot p(x) &|\int f(x) \cdot p(x) \partial x
% \end{cases}$\\
% %$\mathbb{E}_x[f(x)] = \int f(x) \cdot p(x) \partial x $\\
% $\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]$\\
% $\sigma_X^2=Var[X] = \mathbb{E}[(X-\mu_X)^2] = \mathbb{E}[X^2] - \mathbb{E}[X]^2$\\
% $p(Z|X,\theta) = \frac{p(X,Z|\theta)}{p(X|\theta)}$
%\subsection*{Linearity of expectation}
%$X, Y$ rand. var., $a, b \in \mathbb{R}$:\\
%$\mathbb{E}_{x,y}[aX + bY] = a\mathbb{E}_x[X] + b \mathbb{E}_y[Y]$

%-------------------------------------------------------------------------------------------
%Calculus and stuff
%-------------------------------------------------------------------------------------------


% $ln(x) \leq x - 1, x>0$; $||x||_2 = \sqrt{x^T x}$; $\nabla_x ||x||_2^2 = 2 x$%; $||x||_p = (\sum_{i=1}^n|x_i|^p)^{\frac{1}{p}}$, $1 \leq p < \infty$

% $f(x) = x^T A x$; $\nabla_x f(x) = (A + A^T) x$

% $D_{KL} = \mathbb{E}_p[log(\frac{p(x)}{q(x)})]$; $D_{KL} (P||Q) = \sum_{x \in X}P(x) \cdot log \frac{P(x)}{Q(x)} =  \int_{-\infty}^{+\infty} p(x) log \frac{p(x)}{q(x)} \, dx $ always nonneg

\textbf{Orth:} A: $det(A)\in\{+1,-1\},AA^T=A^TA=I$\\
\(trace(ABC) = trace(BCA) = trace(CAB)\)\\ 
\(trace(A)=\sum \lambda_i(A);
% $, A\in\mathbb{R}^{n\times n}, (A^{-1})^T=(A^T)^{-1}$\\
% $rank(A)=n, det(A)\neq0$\\
\begin{bmatrix}
a&b \\ 
c&d
\end{bmatrix}^{-1}=\frac{1}{ad-bc}
\begin{bmatrix}
d&-b \\ 
-c&a
\end{bmatrix}
\)

\(A=\sum_{k=1}^{rk(A)}\sigma_{k,k}u_k (v_k)^T, A^\dag = U S' V^T; \sigma'_{k, k} = \frac{1}{\sigma_{k,k}}\)

\textbf{Deriv:}
$\frac{\partial}{\partial x}b^Tx=\frac{\partial}{\partial x}x^Tb=b^T,\!
\frac{\partial}{\partial x}||x||_2^2=2x^T,\! \frac{\partial}{\partial x} ||x -a||_2 = \frac{(x-a)^T}{||x-a||_2},\!
\frac{\partial}{\partial x}(x^TAx)=x^T(A^T+A),$
$\frac{\partial}{\partial x}(b^TAx)=A^Tb, \nabla_X(c^TXb)=cb^T,
\nabla_X(c^TX^Tb)=bc^T; ||A||_{op} = sup_{||x||_2=1}||Ax||_2$

$\textbf{convex} \iff f(\lambda x+ (1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y); 
f(y) \geq f(x) + \langle\nabla f(x), y-x\rangle; D^2f(x) \geq 0$\\
\(\alpha f + \beta g \textbf{ c.}; \max(f, g) \textbf{ c.} \text{ if } f, g \textbf{ c.}, \alpha, \beta \geq 0\)\\
\(f \circ g = f(g(x)) \textbf{ c.} \text{ if } f \textbf{ c.}, g \textbf{ a.} \lor f \textbf{c., non-dec.}, g \textbf{ c.}\)
% \textbf{Eigdec:}
% $A,Q \in \mathbb{R}^{n\times n}, A=Q\Lambda Q^{-1},\! \Lambda = diag(\lambda_i)$\\
% $Q=[v_1,..,v_n], \text{(col's are e-vec.)}$\\
% $\text{if all $\lambda_i\geq0:$} A^{-1}=Q\Lambda^{-1}Q^{-1},\Lambda^{-1}=diag(\frac{1}{\lambda_i})$\\
% $\text{if }A=A^T\text{(symm.) and }x^TAx\geq0 \forall x \neq 0 \rightarrow psd$\\

% $X\in \mathbb{R}^{n\times p}, U\in \mathbb{R}^{n\times n}, S\in \mathbb{R}^{n\times p},
% V\in \mathbb{R}^{p\times p}$\\
% $X^TX=VS^TU^TUSV^T=VS^TSV^T=V\Sigma V^T$\\
% $\Sigma = diag(\sigma_1^2,..,\sigma_n^2);\sigma_i^2=\lambda_i; \forall \lambda_i \geq 0$
\(p_{\mu, \Sigma}(x)=\frac{1}{\sqrt{(2\pi)^p det(\Sigma)}}\exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))\)\\
\(\mathbf{X} \sim \mathcal{N}(\mu, \Sigma) \implies A\mathbf{X} + b \sim \mathcal{N}(A\mu+b, A\Sigma A^T)\)

% \textbf{Gauss CDF:}\\
% $\Phi(u;v,w) = \int_{-\infty}^{u} \mathcal{N}(y;v,w)dy=\Phi(\frac{u-v}{\sqrt{w}};0,1)$;\\ %CDF: cumulative distribution function; PDF: standard normal probability density function, $\mu = 0$, $\sigma = 1$
%PDF: $\phi(x) = \frac{1}{\sqrt{2\pi}} e^{-(1/2)x^2}$; $\int \phi(x) \partial x = \Phi(x) + c$;\\
%$\int x \phi(x) = -\phi(x) + c$; $\int x^2 \phi(x) \partial x = \Phi(x) -x \phi(x) + c$
\textbf{Jensen ineq: }$g(E[X]) \leq E[g(X)]$, $g$ convex

